{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bittensorflowconda5a27975b90f74b9cb9ff279c942b4bdc",
   "display_name": "Python 3.7.6 64-bit ('tensorflow': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Required Packages  :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os, sys, shutil\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers, applications\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras import optimizers,regularizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import TensorBoard , ModelCheckpoint\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "import zipfile\n",
    "import time\n",
    "import tempfile\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacth_size = 16\n",
    "epochs = 30\n",
    "warmup_epocks = 2\n",
    "learning_rate = 0.0005\n",
    "warmup_learning_rate = 0.0001\n",
    "height = 128\n",
    "width = 128\n",
    "colors = 3\n",
    "n_classes = 5\n",
    "es_patience = 18\n",
    "rlrop_patience = 5\n",
    "decay_drop = 0.5\n",
    "based_model_last_block_layer_number = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/asus/Desktop/images/train'\n",
    "validation_dir = 'C:/Users/asus/Desktop/images/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Augmentation :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1/255,\n",
    "      rotation_range=10,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.5,\n",
    "      brightness_range=[0.7,1.3],\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2716 images belonging to 5 classes.\n"
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(height, width),\n",
    "        batch_size= bacth_size,\n",
    "        shuffle = True,\n",
    "        class_mode= 'categorical')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 941 images belonging to 5 classes.\n"
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(height, width),\n",
    "        batch_size = bacth_size,\n",
    "        shuffle=True,\n",
    "        class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.layers import Flatten,GlobalMaxPooling2D\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Creation : **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = applications.Xception(weights='imagenet', #à modifier\n",
    "                                       include_top=False,\n",
    "                                       input_tensor=input_tensor)\n",
    "    x= GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(1028, activation='elu',kernel_regularizer=regularizers.l2(0.001), name='output')(x)\n",
    "    output = Dropout(0.5)(output)\n",
    "    model_prim = Model(input_tensor, output)\n",
    "    final_output = Dense(n_out, activation='softmax',kernel_regularizer=regularizers.l2(0.001), name='final_output')(model_prim.output)\n",
    "    model = Model(input_tensor, final_output)\n",
    "\n",
    "    return model\n",
    "model = create_model(input_shape=(height, width, colors), n_out=n_classes)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 4, 4, 1024)   745472      add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 4, 4, 1024)   4096        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_11[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\noutput (Dense)                  (None, 1028)         2106372     dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 1028)         0           output[0][0]                     \n__________________________________________________________________________________________________\nfinal_output (Dense)            (None, 5)            5145        dropout_1[0][0]                  \n==================================================================================================\nTotal params: 22,972,997\nTrainable params: 22,899,109\nNon-trainable params: 73,888\n__________________________________________________________________________________________________\n2716\n"
    }
   ],
   "source": [
    "\n",
    "for layer in model.layers[:based_model_last_block_layer_number]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[based_model_last_block_layer_number:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "metric_list = [\"accuracy\"]\n",
    "optimizer = optimizers.Adam(lr=warmup_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",  metrics=metric_list)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Early Stopping :\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=es_patience, verbose=1)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=rlrop_patience, factor=decay_drop, min_lr=1e-6, verbose=1)\n",
    "\n",
    "\n",
    "step_train = train_generator.n//train_generator.batch_size\n",
    "step_validation = val_generator.n//val_generator.batch_size\n",
    "\n",
    "print(train_generator.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Writing training logs to C:\\Users\\asus\\AppData\\Local\\Temp\\tmpj_e7ydcx\n"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=step_train,\n",
    "                              epochs=30,\n",
    "                              verbose=1 ,\n",
    "                              callbacks=callbacks,                            \n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=step_validation\n",
    "\n",
    "                            ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Xception_images.h5')\n",
    "\n",
    "train_data = pd.read_csv('C:/Users/asus/Desktop/retino/train.csv')\n",
    "test_data = pd.read_csv('C:/Users/asus/Desktop/retino/test.csv')\n",
    "\n",
    "train_path = 'C:/Users/asus/Desktop/retino/images/train'\n",
    "test_path = 'C:/Users/asus/Desktop/retino/images/test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Preprocessing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, desired_size=128):\n",
    "    im = Image.open(image_path)\n",
    "    im = im.resize((desired_size,) * 2, resample=Image.LANCZOS)\n",
    "\n",
    "    return im\n",
    "\n",
    "N = train_data.shape[0]\n",
    "\n",
    "x_train = np.empty((N, 128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "for i, image_id in enumerate(tqdm(train_data['id_code'])):\n",
    "    x_train[i, :, :, :] = preprocess_image(\n",
    "        os.path.join(train_path + \"/\" + image_id + '.png')\n",
    "    )\n",
    "\n",
    "x_train = x_train / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predictions :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 3662/3662 [15:59<00:00,  3.82it/s]\nStarted predicting at 2020-04-22 11:19:34.413887\nPredicting took a total of 0:01:25.824835\n"
    }
   ],
   "source": [
    "\n",
    "# use the model to generate predictions for all of the training images\n",
    "start = datetime.datetime.now()\n",
    "print('Started predicting at {}'.format(start))\n",
    "\n",
    "train_prediction = model.predict([x_train])\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Predicting took a total of {}'.format(elapsed))\n",
    "\n",
    "# take the highest predicted probability for each image\n",
    "train_predictions = [np.argmax(pred) for pred in train_prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The model Performance :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at how the model performed for each class\n",
    "labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\n",
    "cnf_matrix = confusion_matrix(train_data['diagnosis'].astype('int'), train_predictions)\n",
    "cnf_matrix_norm = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cnf_matrix_norm, index=labels, columns=labels)\n",
    "plt.figure(figsize=(16, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pruning :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Saving model to:  C:\\Users\\asus\\AppData\\Local\\Temp\\tmphya3uqs9.h5\n"
    }
   ],
   "source": [
    "# Backend agnostic way to save/restore models\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "End step: 2290\n"
    }
   ],
   "source": [
    "epochs = 10\n",
    "num_train_samples = x_train.shape[0]\n",
    "end_step = np.ceil(1.0 * num_train_samples / train_generator.batch_size).astype(np.int32) * epochs\n",
    "print('End step: ' + str(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=end_step)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pruned Model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = tf.keras.layers\n",
    "\n",
    "pruned_model = tf.keras.Sequential()\n",
    "    \n",
    "for layer in model.layers:\n",
    "\n",
    "    if (layer.name == 'output') or (layer.name == 'final_output') or (layer.name == 'block_conv1') or (layer.name == 'block_conv2') or (layer.name == 'conv2d_1'):\n",
    "        pruned_model.add(sparsity.prune_low_magnitude(layer,input_shape=(height, width, colors),**pruning_params))\n",
    "    else:\n",
    "        try:\n",
    "            pruned_model.add(layer)\n",
    "        except ValueError:\n",
    "               pass\n",
    "\n",
    "model = pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
    "# step. Also add a callback to add pruning summaries to tensorboard\n",
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "history_1 = pruned_model.fit(train_generator,\n",
    "          steps_per_epoch=step_train,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=val_generator).history\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, checkpoint_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', checkpoint_file)\n",
    "# saved_model() sets include_optimizer to True by default. Spelling it out here\n",
    "# to highlight.\n",
    "tf.keras.models.save_model(pruned_model, checkpoint_file, include_optimizer=True)\n",
    "\n",
    "with sparsity.prune_scope():\n",
    "  restored_model = tf.keras.models.load_model(checkpoint_file)\n",
    "\n",
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "history_2 = restored_model.fit(train_generator,\n",
    "                    steps_per_epoch=step_train,\n",
    "                   epochs=5,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data=val_generator).history\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = sparsity.strip_pruning(pruned_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use the model to generate predictions for all of the training images\n",
    "start = datetime.datetime.now()\n",
    "print('Started predicting at {}'.format(start))\n",
    "\n",
    "train_prediction = final_model.predict([x_train])\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Predicting took a total of {}'.format(elapsed))\n",
    "\n",
    "# take the highest predicted probability for each image\n",
    "train_predictions = [np.argmax(pred) for pred in train_prediction]\n",
    "\n",
    "# look at how the model performed for each class\n",
    "labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\n",
    "cnf_matrix = confusion_matrix(train_data['diagnosis'].astype('int'), train_predictions)\n",
    "cnf_matrix_norm = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cnf_matrix_norm, index=labels, columns=labels)\n",
    "plt.figure(figsize=(16, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_2['accuracy'])\n",
    "plt.plot(history_2['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_2['loss'])\n",
    "plt.plot(history_2['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', pruned_keras_file)\n",
    "\n",
    "# No need to save the optimizer with the graph for serving.\n",
    "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of  size of the  pruned /unpruned model before and after compression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, zip1 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(keras_file)\n",
    "print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(keras_file) / float(2**20)))\n",
    "print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip1) / float(2**20)))\n",
    "\n",
    "_, zip2 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip2, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip2) / float(2**20)))\n",
    "\n",
    ""
   ]
  }
 ]
}